{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "nIkPUTxxIfal"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import glob\n",
        "import cv2\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOBm-KLWzxjT",
        "outputId": "1b8fcbfe-3589-4976-9bfa-f1133fa8b3da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 16 15:51:18 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount google drive"
      ],
      "metadata": {
        "id": "mkb-slyaIwFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "metadata": {
        "id": "Q4RDRsiJI2Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone and build Darknet"
      ],
      "metadata": {
        "id": "B4n7p3EJP-O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone darknet repo\n",
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QRwybCsQuxK",
        "outputId": "606a389a-4ea8-444c-934d-5b264280a930"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 15502, done.\u001b[K\n",
            "remote: Total 15502 (delta 0), reused 0 (delta 0), pack-reused 15502\u001b[K\n",
            "Receiving objects: 100% (15502/15502), 14.15 MiB | 22.39 MiB/s, done.\n",
            "Resolving deltas: 100% (10404/10404), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify makefile to have GPU and OPENCV enabled\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n",
        "\n",
        "# Compile darknet\n",
        "!make"
      ],
      "metadata": {
        "id": "UbwKtRCDREI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset in Cloud"
      ],
      "metadata": {
        "id": "UYibbxoWVLxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store custom data in Google drive\n",
        "!ls /mydrive/yolov3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG-ra5STVQWr",
        "outputId": "dcb198b4-1233-4dc9-a806-18e53c92f420"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "backup\t\t    obj.data\t\t\t  yolov3_custom.cfg\n",
            "generate_train.py   obj.names\t\t\t  yolov3_testing.cfg\n",
            "Huli_and_Fence.zip  train_YOLOv3_colab_GPU.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the .zip file to the root directory of cloud VM\n",
        "!cp /mydrive/yolov3/Huli_and_Fence.zip ../"
      ],
      "metadata": {
        "id": "Owh_yHXKVWh4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file and store into /darknet/data/ojb directory\n",
        "!unzip ../Huli_and_Fence.zip -d data/obj"
      ],
      "metadata": {
        "id": "NuAqGcIEV5Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get & edit YOLOv3 Configuration file\n",
        "* Make a copy & rename the original yolov3 config file;\n",
        "* Update Config file -> classes & filters:\n",
        "  1. `max_batches` = num_classes * 2000\n",
        "  2. `steps` = 0.8 * `max_batches`, 0.2 * `max_batches`\n",
        "  3. `classes` = 3 in three YOLO layers\n",
        "  4. `filters` = (`classes` + 4 + 1) * 3 in three conv layers right before YOLO layers"
      ],
      "metadata": {
        "id": "6SqOrKvVRMmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of original yolov3.cfg file and rename it for training\n",
        "!cp cfg/yolov3.cfg /mydrive/yolov3/yolov3_custom.cfg"
      ],
      "metadata": {
        "id": "1HvFZa5kRaXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of original yolov3.cfg file and rename it for testing\n",
        "!cp cfg/yolov3.cfg /mydrive/yolov3/yolov3_testing.cfg"
      ],
      "metadata": {
        "id": "LSfouorosG-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the modified .cfg file to cloud VM\n",
        "!cp /mydrive/yolov3/yolov3_custom.cfg ./cfg\n",
        "!cp /mydrive/yolov3/yolov3_testing.cfg ./cfg"
      ],
      "metadata": {
        "id": "OunP1_tBW9uB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and prepare dataset for training process\n",
        "* Create a new directory in darknet/data/ directory & upload dataset\n",
        "* Create classes.names & training.data\n",
        "* Create training.txt file"
      ],
      "metadata": {
        "id": "g29iN8lWRz5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create .names and .data files required for darknet framework\n",
        "!echo -e 'Huli\\nDog\\nFence' >> data/obj.names\n",
        "!echo -e 'classes = 3\\ntrain = data/train.txt\\nvalid = data/test.txt\\nnames = data/obj.names\\nbackup = /mydrive/yolov3/backup' >> data/obj.data"
      ],
      "metadata": {
        "id": "OxqnRhzTUD_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy generated files to /data directory\n",
        "!cp /mydrive/yolov3/obj.names ./data\n",
        "!cp /mydrive/yolov3/obj.data  ./data"
      ],
      "metadata": {
        "id": "jhdVh2ZoZ9fJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get full path of all images\n",
        "images_list = glob.glob(\"data/obj/Huli_and_Fence/*[jpg|png|jpeg]\")\n",
        "print(images_list)"
      ],
      "metadata": {
        "id": "2MtkLcaddEyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images_list)"
      ],
      "metadata": {
        "id": "AGeDGQRngnoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train set and test set\n",
        "split_size = int(len(images_list)*0.15)\n",
        "\n",
        "# For reproducibility\n",
        "random.seed(42)\n",
        "# Shuffle data to remove any possible patterns\n",
        "random.shuffle(images_list)\n",
        "train_data = images_list[:-split_size]\n",
        "test_data = images_list[-split_size:]"
      ],
      "metadata": {
        "id": "NPIVK443fihL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "Ud4O-eJlgBIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train.txt file containing paths of training images\n",
        "file = open(\"data/train.txt\", \"w\") \n",
        "file.write(\"\\n\".join(train_data))\n",
        "file.close()"
      ],
      "metadata": {
        "id": "c3rWmpT1feSN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test.txt file containing paths of testing images\n",
        "file = open(\"data/test.txt\", \"w\") \n",
        "file.write(\"\\n\".join(test_data))\n",
        "file.close()"
      ],
      "metadata": {
        "id": "UoyS2dREpOwO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download YOLOv3 pretrained weights"
      ],
      "metadata": {
        "id": "8zoQtoSqgixc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get pretrained convolutional layers weights\n",
        "!wget https://pjreddie.com/media/files/darknet53.conv.74"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQUZl58Lg7Ax",
        "outputId": "1e1c8cb7-3520-424b-d38c-0e854abfa283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-14 12:12:29--  https://pjreddie.com/media/files/darknet53.conv.74\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162482580 (155M) [application/octet-stream]\n",
            "Saving to: ‘darknet53.conv.74’\n",
            "\n",
            "darknet53.conv.74   100%[===================>] 154.96M  16.5MB/s    in 9.8s    \n",
            "\n",
            "2023-02-14 12:12:39 (15.8 MB/s) - ‘darknet53.conv.74’ saved [162482580/162482580]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on custom data"
      ],
      "metadata": {
        "id": "RN8272ptg9nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv3 on custom data\n",
        "!./darknet detector train data/obj.data cfg/yolov3_custom.cfg darknet53.conv.74 -dont_show"
      ],
      "metadata": {
        "id": "14_-zsf1hBL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue training from where it left off\n",
        "!./darknet detector train data/obj.data cfg/yolov3_custom.cfg /mydrive/yolov3/backup/yolov3_custom_last.weights -dont_show"
      ],
      "metadata": {
        "id": "rrwPVDdz2eQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate trained model on test data\n",
        "\n",
        "Calculate Mean Average Precision(MAP) of the trained model with weights of different stage."
      ],
      "metadata": {
        "id": "x80qKYsWkVw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Average Precision(MAP) of the trained model with weights of different stage\n",
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_6000.weights"
      ],
      "metadata": {
        "id": "rQHiYT15rh6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_5000.weights"
      ],
      "metadata": {
        "id": "QFlOk2IKu1I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_4000.weights"
      ],
      "metadata": {
        "id": "hHcvykjf8vu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_3000.weights"
      ],
      "metadata": {
        "id": "mout9Y1T86P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_2000.weights"
      ],
      "metadata": {
        "id": "gC9t6Za09EeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_1000.weights"
      ],
      "metadata": {
        "id": "ctXwsHTP9PKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov3_testing.cfg /mydrive/yolov3/backup/yolov3_custom_final.weights"
      ],
      "metadata": {
        "id": "wQkJbVSK9ZbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on image sample"
      ],
      "metadata": {
        "id": "HJcRoUdp9oWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper function to show results\n",
        "def imShow(path):\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "xBv9PuHh_TrA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect objects from sample iamge\n",
        "!./darknet detector test data/obj.data cfg/yolov3_custom.cfg /mydrive/yolov3/backup/yolov3_custom_last.weights /mydrive/yolov3/IMG_7033.jpg -thresh 0.3\n",
        "imShow('predictions.jpg')"
      ],
      "metadata": {
        "id": "tAvOeSqr_5XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv3 on Webcam Videos"
      ],
      "metadata": {
        "id": "_Ugjv7YFCERA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhrQqPc2HR27"
      },
      "source": [
        "# Import darknet functions to perform object detections\n",
        "from darknet import *\n",
        "# Load in custom trained YOLOv3 architecture network\n",
        "network, class_names, class_colors = load_network(\"cfg/yolov3_custom.cfg\", \"data/obj.data\", \"/mydrive/yolov3/backup/yolov3_custom_last.weights\")\n",
        "width = network_width(network)\n",
        "height = network_height(network)\n",
        "\n",
        "# darknet helper function to run detection on image\n",
        "def darknet_helper(img, width, height):\n",
        "  darknet_image = make_image(width, height, 3)\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img_resized = cv2.resize(img_rgb, (width, height),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # Get image ratios to convert bounding boxes to proper size\n",
        "  img_height, img_width, _ = img.shape\n",
        "  width_ratio = img_width/width\n",
        "  height_ratio = img_height/height\n",
        "\n",
        "  # Run model on darknet style image to get detections\n",
        "  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "  detections = detect_image(network, class_names, darknet_image)\n",
        "  free_image(darknet_image)\n",
        "  \n",
        "  return detections, width_ratio, height_ratio"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zg82Yi292ku"
      },
      "source": [
        "# Define function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# Define function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # Convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # Format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # Format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZk68RUQW3Xq"
      },
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RPDr23YFW_7c",
        "outputId": "125a7c98-ad52-49fd-fb4f-f0436652b33d"
      },
      "source": [
        "# Start streaming video from webcam\n",
        "video_stream()\n",
        "# Label for video\n",
        "label_html = 'Capturing...'\n",
        "# Initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # Convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # Create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # Call our darknet helper on video frame\n",
        "    detections, width_ratio, height_ratio = darknet_helper(frame, width, height)\n",
        "\n",
        "    # Loop through detections and draw them on transparent overlay image\n",
        "    for label, confidence, bbox in detections:\n",
        "      left, top, right, bottom = bbox2points(bbox)\n",
        "      left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n",
        "      bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), class_colors[label], 2)\n",
        "      bbox_array = cv2.putText(bbox_array, \"{} [{:.2f}]\".format(label, float(confidence)),\n",
        "                        (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        class_colors[label], 2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # Convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # Update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}